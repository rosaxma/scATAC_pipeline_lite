import os
from snakemake.utils import min_version

min_version("7.8.0")

configfile: 
    "config/config.yaml"

with open(config["sample_table"]) as sample_file:
    h = ["#"]
    while h[0].startswith("#"):
        h = sample_file.readline().rstrip('\n').split('\t')
    sample_ind = h.index("Sample")
    lanes_ind = h.index("Lanes")
    path_ind = h.index("Path")
    samples = []
    sample_data = {}
    for line in sample_file:
        if line.startswith("#"):
            continue
        entries = line.rstrip('\n').split('\t')
        sample = entries[sample_ind]
        lanes = entries[lanes_ind].split(",")
        path_template = os.path.join(config["input_dir"], entries[path_ind])
        samples.append(sample)
        sample_data[sample] = (lanes, path_template)
workdir: 
    config['workdir']

max_threads = config["max_threads_per_rule"]

def script_path(script_name):
    return str(workflow.source_path(script_name))

include:
    "rules/chromap.smk"
include:
    "rules/bowtie.smk"
include:
    "rules/fragments.smk"

rule all:
    """
    Generate all outputs (default)
    """
    input: 
        #expand(os.path.join(config["output_dir"], "{sample}/alignments_sorted.bam"), sample=samples),
        expand(os.path.join(config["output_dir"], "{sample}/alignments_sorted.bam.bai"), sample=samples),
        expand(os.path.join(config["output_dir"], "{sample}/markdup.txt"), sample=samples),
        expand(os.path.join(config["output_dir"], "{sample}/fragments.tsv.gz"), sample=samples),
        expand(os.path.join(config["output_dir"], "{sample}/fragments.tsv.gz.tbi"), sample=samples),
	#expand(os.path.join(config["output_dir"], "{sample}/processing_QC/bwt2_stats.txt"),sample=samples),
	#expand(os.path.join(config["output_dir"], "{sample}/processing_QC/barcode_matching_full.tsv"),sample=samples),

def fetch_fastq(w):
    read_name = config["read_names"][w.read]
    lanes, path_template = sample_data[w.sample]
    fastqs = [path_template.format(lane=l, read=read_name) for l in lanes]
    return fastqs

rule organize_fastqs:
    """
    Concatenate and organize input FASTQs
    """
    input:
        fetch_fastq
    output:
        "fastqs/{sample}/{read}.fastq.gz"
    resources:
        mem_mb = 1000,
        runtime_min = 1440
    conda:
        "envs/fetch.yaml"
    shell:
        "zcat -f {input} | sed 's/ .*//' | gzip -c > {output}"

rule fetch_whitelist:
    """
    Fetch barcode whitelist
    """
    output:
        "bc_whitelist.txt"
    params:
        #url = config["whitelist_paths"][config["whitelist_choice"]],
        barcode = config["whitelist_paths"][config["whitelist_choice"]],
        prefix = config["bc_prefix"],
        suffix = config["bc_suffix"],
        rc_command = "tr ACGTacgt TGCAtgca | rev " if config["whitelist_revcomp"] else "cat "
    resources:
        mem_mb = 1000
    conda:
        "envs/fetch.yaml"
    shell:
        "zcat {params.barcode}| {params.rc_command} | "
        "sed -e 's/^/{params.prefix}/' -e 's/$/{params.suffix}/' > {output}"

rule fetch_genome:
    """
    Fetch genome FASTA
    """
    output:
        "genomes/genome.fa"
    params:
        url = config["genome"]
    resources:
        mem_mb = 1000
    conda:
        "envs/fetch.yaml"
    shell:
        "curl -sS -L {params.url} | zcat -f > {output}"

rule organize_output_bams:
    """
    Organize output BAM files
    """
    input:
        "results/{sample}/alignments_sorted.bam"
    output:
        os.path.join(config["output_dir"], "{sample}/alignments_sorted.bam")
    params:
        url = config["genome"]
    resources:
        mem_mb = 16000,
        runtime_min = 480
    conda:
        "envs/fetch.yaml"
    shell:
        "mkdir -p `dirname {output}`; "
        "cp {input} {output}"

rule organize_output_markup:
    """
    Organize markup results
    """
    input:
        "results/{sample}/bwt2/markdup.txt"
    output:
        os.path.join(config["output_dir"], "{sample}/markdup.txt")
    resources:
        mem_mb = 16000,
        runtime_min = 480
    conda:
        "envs/fetch.yaml"
    shell:
        "mkdir -p `dirname {output}`; "
        "cp {input} {output}"


rule index_output_bams:
    """
    Index output BAM files
    """
    input:
        os.path.join(config["output_dir"], "{sample}/alignments_sorted.bam")
    output:
        os.path.join(config["output_dir"], "{sample}/alignments_sorted.bam.bai")
    resources: 
        mem_mb=64000,
        runtime_min=480
    conda:
	    "envs/bwt2.yaml"
    shell:
	    "samtools index {input}" 
	

rule organize_output_fragments:
    """
    Organize output fragment files
    """
    input:
        frag = "results/{sample}/fragments.tsv.gz",
        frag_ind = "results/{sample}/fragments.tsv.gz.tbi"
    output:
        frag = os.path.join(config["output_dir"], "{sample}/fragments.tsv.gz"),
        frag_ind = os.path.join(config["output_dir"], "{sample}/fragments.tsv.gz.tbi")
    params:
        url = config["genome"]
    resources:
        mem_mb = 16000,
        runtime_min = 480
    conda:
        "envs/fetch.yaml"
    shell:
        "mkdir -p `dirname {output.frag}`; "
        "cp {input.frag} {output.frag}; "
        "cp {input.frag_ind} {output.frag_ind}"

rule get_multimapped_reads:
    """
    Get the effects of "filter_multimappers"
    """
    input:
        raw_bam="results/{sample}/bwt2/raw_collated.bam",
        primary_align_bam="results/{sample}/bwt2/primary_align.bam"
    output:
        os.path.join(config["output_dir"], "{sample}/QC/comparison_before_vs_after_filter.txt")
    resources:
        mem_mb = 256000,
        runtime_min = 480
    conda:
        "envs/bwt2.yaml"
    shell:
        """
        java -Xms80g -jar /scratch/users/rosaxma/scATAC/.snakemake/conda/6c156abdc2ff10ab9d942563bf922988/share/picard-slim-2.25.7-0/picard.jar CompareSAMs {input.raw_bam} {input.primary_align_bam} O={output}
        """


rule organize_output_qc_files:
    """
    Organize all qc outputs
    """
    input:
        qc_mito = "results/{sample}/frac_mito.tsv",
        qc_bwt2 = "results/{sample}/bwt2/bwt2_stats.txt",
        adapter_stats = "results/{sample}/bwt2/trim_adapters.txt",
        bc_qc="results/{sample}/bwt2/barcode_matching_full.tsv"
    output:
        mito=os.path.join(config["output_dir"], "{sample}/processing_QC/frac_mito.tsv"),
        bwt2=os.path.join(config["output_dir"], "{sample}/processing_QC/bwt2_stats.txt"),
        adapter=os.path.join(config["output_dir"], "{sample}/processing_QC/trim_adapters.txt"),
        bc=os.path.join(config["output_dir"], "{sample}/processing_QC/barcode_matching_full.tsv"),
    resources:
        mem_mb = 16000,
        runtime_min = 480
    conda:
        "envs/fetch.yaml"
    shell:
        """
        cp {input.qc_mito} {output.mito}
        cp {input.qc_bwt2} {output.bwt2}
        cp {input.adapter_stats} {output.adapter}
        cp {input.bc_qc} {output.bc}
        """


